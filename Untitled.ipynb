{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" This simple code is desinged to teach a basic user to read in the files in python, simply find what proportion of males and females survived and make a predictive model based on this\n",
    "Author : AstroDave\n",
    "Date : 18 September 2012\n",
    "Revised: 28 March 2014\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import csv as csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_file_object = csv.reader(open('./data/train.csv', 'rb')) \t# Load in the csv file\n",
    "header          = csv_file_object.next() \t\t\t\t\t\t# Skip the fist line as it is a header\n",
    "data            =[] \t\t\t\t\t\t\t\t\t\t\t# Create a variable to hold the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in csv_file_object: \t\t\t\t\t\t\t# Skip through each row in the csv file,\n",
    "    data.append(row[0:]) \t\t\t\t\t\t\t\t# adding each row to the data variable\n",
    "data = np.array(data) \t\t\t\t\t\t\t\t\t# Then convert from a list to an array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', '0', '3', ..., '7.25', '', 'S'],\n",
       "       ['2', '1', '1', ..., '71.2833', 'C85', 'C'],\n",
       "       ['3', '1', '3', ..., '7.925', '', 'S'],\n",
       "       ..., \n",
       "       ['889', '0', '3', ..., '23.45', '', 'S'],\n",
       "       ['890', '1', '1', ..., '30', 'C148', 'C'],\n",
       "       ['891', '0', '3', ..., '7.75', '', 'Q']], \n",
       "      dtype='|S82')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing w/ the data\n",
    "\n",
    "I have an array of 12 columns and 891 rows.\n",
    "I can access any element I want, so the entire first column would be `data[0::,0].astype(np.float)`\n",
    "-- This means all of the rows (from start to end), in column 0 I have to add the .astype() command, because when appending the rows, python thought it was a string - so needed to convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1.,    2.,    3.,    4.,    5.,    6.,    7.,    8.,    9.,\n",
       "         10.,   11.,   12.,   13.,   14.,   15.,   16.,   17.,   18.,\n",
       "         19.,   20.,   21.,   22.,   23.,   24.,   25.,   26.,   27.,\n",
       "         28.,   29.,   30.,   31.,   32.,   33.,   34.,   35.,   36.,\n",
       "         37.,   38.,   39.,   40.,   41.,   42.,   43.,   44.,   45.,\n",
       "         46.,   47.,   48.,   49.,   50.,   51.,   52.,   53.,   54.,\n",
       "         55.,   56.,   57.,   58.,   59.,   60.,   61.,   62.,   63.,\n",
       "         64.,   65.,   66.,   67.,   68.,   69.,   70.,   71.,   72.,\n",
       "         73.,   74.,   75.,   76.,   77.,   78.,   79.,   80.,   81.,\n",
       "         82.,   83.,   84.,   85.,   86.,   87.,   88.,   89.,   90.,\n",
       "         91.,   92.,   93.,   94.,   95.,   96.,   97.,   98.,   99.,\n",
       "        100.,  101.,  102.,  103.,  104.,  105.,  106.,  107.,  108.,\n",
       "        109.,  110.,  111.,  112.,  113.,  114.,  115.,  116.,  117.,\n",
       "        118.,  119.,  120.,  121.,  122.,  123.,  124.,  125.,  126.,\n",
       "        127.,  128.,  129.,  130.,  131.,  132.,  133.,  134.,  135.,\n",
       "        136.,  137.,  138.,  139.,  140.,  141.,  142.,  143.,  144.,\n",
       "        145.,  146.,  147.,  148.,  149.,  150.,  151.,  152.,  153.,\n",
       "        154.,  155.,  156.,  157.,  158.,  159.,  160.,  161.,  162.,\n",
       "        163.,  164.,  165.,  166.,  167.,  168.,  169.,  170.,  171.,\n",
       "        172.,  173.,  174.,  175.,  176.,  177.,  178.,  179.,  180.,\n",
       "        181.,  182.,  183.,  184.,  185.,  186.,  187.,  188.,  189.,\n",
       "        190.,  191.,  192.,  193.,  194.,  195.,  196.,  197.,  198.,\n",
       "        199.,  200.,  201.,  202.,  203.,  204.,  205.,  206.,  207.,\n",
       "        208.,  209.,  210.,  211.,  212.,  213.,  214.,  215.,  216.,\n",
       "        217.,  218.,  219.,  220.,  221.,  222.,  223.,  224.,  225.,\n",
       "        226.,  227.,  228.,  229.,  230.,  231.,  232.,  233.,  234.,\n",
       "        235.,  236.,  237.,  238.,  239.,  240.,  241.,  242.,  243.,\n",
       "        244.,  245.,  246.,  247.,  248.,  249.,  250.,  251.,  252.,\n",
       "        253.,  254.,  255.,  256.,  257.,  258.,  259.,  260.,  261.,\n",
       "        262.,  263.,  264.,  265.,  266.,  267.,  268.,  269.,  270.,\n",
       "        271.,  272.,  273.,  274.,  275.,  276.,  277.,  278.,  279.,\n",
       "        280.,  281.,  282.,  283.,  284.,  285.,  286.,  287.,  288.,\n",
       "        289.,  290.,  291.,  292.,  293.,  294.,  295.,  296.,  297.,\n",
       "        298.,  299.,  300.,  301.,  302.,  303.,  304.,  305.,  306.,\n",
       "        307.,  308.,  309.,  310.,  311.,  312.,  313.,  314.,  315.,\n",
       "        316.,  317.,  318.,  319.,  320.,  321.,  322.,  323.,  324.,\n",
       "        325.,  326.,  327.,  328.,  329.,  330.,  331.,  332.,  333.,\n",
       "        334.,  335.,  336.,  337.,  338.,  339.,  340.,  341.,  342.,\n",
       "        343.,  344.,  345.,  346.,  347.,  348.,  349.,  350.,  351.,\n",
       "        352.,  353.,  354.,  355.,  356.,  357.,  358.,  359.,  360.,\n",
       "        361.,  362.,  363.,  364.,  365.,  366.,  367.,  368.,  369.,\n",
       "        370.,  371.,  372.,  373.,  374.,  375.,  376.,  377.,  378.,\n",
       "        379.,  380.,  381.,  382.,  383.,  384.,  385.,  386.,  387.,\n",
       "        388.,  389.,  390.,  391.,  392.,  393.,  394.,  395.,  396.,\n",
       "        397.,  398.,  399.,  400.,  401.,  402.,  403.,  404.,  405.,\n",
       "        406.,  407.,  408.,  409.,  410.,  411.,  412.,  413.,  414.,\n",
       "        415.,  416.,  417.,  418.,  419.,  420.,  421.,  422.,  423.,\n",
       "        424.,  425.,  426.,  427.,  428.,  429.,  430.,  431.,  432.,\n",
       "        433.,  434.,  435.,  436.,  437.,  438.,  439.,  440.,  441.,\n",
       "        442.,  443.,  444.,  445.,  446.,  447.,  448.,  449.,  450.,\n",
       "        451.,  452.,  453.,  454.,  455.,  456.,  457.,  458.,  459.,\n",
       "        460.,  461.,  462.,  463.,  464.,  465.,  466.,  467.,  468.,\n",
       "        469.,  470.,  471.,  472.,  473.,  474.,  475.,  476.,  477.,\n",
       "        478.,  479.,  480.,  481.,  482.,  483.,  484.,  485.,  486.,\n",
       "        487.,  488.,  489.,  490.,  491.,  492.,  493.,  494.,  495.,\n",
       "        496.,  497.,  498.,  499.,  500.,  501.,  502.,  503.,  504.,\n",
       "        505.,  506.,  507.,  508.,  509.,  510.,  511.,  512.,  513.,\n",
       "        514.,  515.,  516.,  517.,  518.,  519.,  520.,  521.,  522.,\n",
       "        523.,  524.,  525.,  526.,  527.,  528.,  529.,  530.,  531.,\n",
       "        532.,  533.,  534.,  535.,  536.,  537.,  538.,  539.,  540.,\n",
       "        541.,  542.,  543.,  544.,  545.,  546.,  547.,  548.,  549.,\n",
       "        550.,  551.,  552.,  553.,  554.,  555.,  556.,  557.,  558.,\n",
       "        559.,  560.,  561.,  562.,  563.,  564.,  565.,  566.,  567.,\n",
       "        568.,  569.,  570.,  571.,  572.,  573.,  574.,  575.,  576.,\n",
       "        577.,  578.,  579.,  580.,  581.,  582.,  583.,  584.,  585.,\n",
       "        586.,  587.,  588.,  589.,  590.,  591.,  592.,  593.,  594.,\n",
       "        595.,  596.,  597.,  598.,  599.,  600.,  601.,  602.,  603.,\n",
       "        604.,  605.,  606.,  607.,  608.,  609.,  610.,  611.,  612.,\n",
       "        613.,  614.,  615.,  616.,  617.,  618.,  619.,  620.,  621.,\n",
       "        622.,  623.,  624.,  625.,  626.,  627.,  628.,  629.,  630.,\n",
       "        631.,  632.,  633.,  634.,  635.,  636.,  637.,  638.,  639.,\n",
       "        640.,  641.,  642.,  643.,  644.,  645.,  646.,  647.,  648.,\n",
       "        649.,  650.,  651.,  652.,  653.,  654.,  655.,  656.,  657.,\n",
       "        658.,  659.,  660.,  661.,  662.,  663.,  664.,  665.,  666.,\n",
       "        667.,  668.,  669.,  670.,  671.,  672.,  673.,  674.,  675.,\n",
       "        676.,  677.,  678.,  679.,  680.,  681.,  682.,  683.,  684.,\n",
       "        685.,  686.,  687.,  688.,  689.,  690.,  691.,  692.,  693.,\n",
       "        694.,  695.,  696.,  697.,  698.,  699.,  700.,  701.,  702.,\n",
       "        703.,  704.,  705.,  706.,  707.,  708.,  709.,  710.,  711.,\n",
       "        712.,  713.,  714.,  715.,  716.,  717.,  718.,  719.,  720.,\n",
       "        721.,  722.,  723.,  724.,  725.,  726.,  727.,  728.,  729.,\n",
       "        730.,  731.,  732.,  733.,  734.,  735.,  736.,  737.,  738.,\n",
       "        739.,  740.,  741.,  742.,  743.,  744.,  745.,  746.,  747.,\n",
       "        748.,  749.,  750.,  751.,  752.,  753.,  754.,  755.,  756.,\n",
       "        757.,  758.,  759.,  760.,  761.,  762.,  763.,  764.,  765.,\n",
       "        766.,  767.,  768.,  769.,  770.,  771.,  772.,  773.,  774.,\n",
       "        775.,  776.,  777.,  778.,  779.,  780.,  781.,  782.,  783.,\n",
       "        784.,  785.,  786.,  787.,  788.,  789.,  790.,  791.,  792.,\n",
       "        793.,  794.,  795.,  796.,  797.,  798.,  799.,  800.,  801.,\n",
       "        802.,  803.,  804.,  805.,  806.,  807.,  808.,  809.,  810.,\n",
       "        811.,  812.,  813.,  814.,  815.,  816.,  817.,  818.,  819.,\n",
       "        820.,  821.,  822.,  823.,  824.,  825.,  826.,  827.,  828.,\n",
       "        829.,  830.,  831.,  832.,  833.,  834.,  835.,  836.,  837.,\n",
       "        838.,  839.,  840.,  841.,  842.,  843.,  844.,  845.,  846.,\n",
       "        847.,  848.,  849.,  850.,  851.,  852.,  853.,  854.,  855.,\n",
       "        856.,  857.,  858.,  859.,  860.,  861.,  862.,  863.,  864.,\n",
       "        865.,  866.,  867.,  868.,  869.,  870.,  871.,  872.,  873.,\n",
       "        874.,  875.,  876.,  877.,  878.,  879.,  880.,  881.,  882.,\n",
       "        883.,  884.,  885.,  886.,  887.,  888.,  889.,  890.,  891.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0::,0].astype(np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proportion of Survivors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of Survivors: 891/342.0 = 0.383838383838\n"
     ]
    }
   ],
   "source": [
    "number_passengers    = np.size(data[0::,1].astype(np.float))\n",
    "number_survived      = np.sum(data[0::,1].astype(np.float))\n",
    "proportion_survivors = number_survived / number_passengers\n",
    "print 'Proportion of Survivors: %s/%s = %s' % (number_passengers \\\n",
    "                                               , number_survived \\\n",
    "                                               , proportion_survivors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats of all women on board\n",
    "Find the stats of all the women on board, by making an array that lists True/False whether each row is female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "women_only_stats = data[0::,4] == \"female\" \t# This finds where all the women are\n",
    "men_only_stats   = data[0::,4] != \"female\" \t# This finds where all the men are (note != means 'not equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the whole data, to find statistics for just women, by just placing women_only_stats as a \"mask\" on my full data -- Use it in place of the '0::' part of the array index. \n",
    "\n",
    "\n",
    "You can test it by placing it there, and requesting column index [4], and the output should all read 'female' e.g. try typing this:   data[women_only_stats,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "women_onboard = data[women_only_stats, 1].astype(np.float)\n",
    "men_onboard   = data[men_only_stats,   1].astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Women onboard: 314\n",
      "Men   onboard: 577\n",
      "Total onboard: 891\n"
     ]
    }
   ],
   "source": [
    "print 'Women onboard: %s' % women_onboard.size\n",
    "print 'Men   onboard: %s' % men_onboard.size\n",
    "print 'Total onboard: %s' % (women_onboard.size+men_onboard.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive some statistics about them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proportion_women_survived = np.sum(women_onboard) / np.size(women_onboard)\n",
    "proportion_men_survived   = np.sum(men_onboard)   / np.size(men_onboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of women who survived is 0.742038216561\n",
      "Proportion of men   who survived is 0.188908145581\n"
     ]
    }
   ],
   "source": [
    "print 'Proportion of women who survived is %s' % proportion_women_survived\n",
    "print 'Proportion of men   who survived is %s' % proportion_men_survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have my indicator that women were much more likely to survive, I am done with the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Basic Model: Women Survive\n",
    "\n",
    "Now I will read in the test file and write out my simplistic prediction:\n",
    "- if female, then model that she survived (1) \n",
    "- if male, then model that he did not survive (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_file        = open('./data/test.csv', 'rb')         # First, read in test.csv\n",
    "test_file_object = csv.reader(test_file)\n",
    "header           = test_file_object.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open a new file so I can write to it. \n",
    "Call it something descriptive.\n",
    "Finally, loop through each row in the train file, and look in column index [3] (which is 'Sex').\n",
    "Write out the PassengerId, and my prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_file        = open(\"./models/jfaPythonBasicGenderModel.csv\", \"wb\")\n",
    "predictions_file_object = csv.writer(predictions_file)\n",
    "predictions_file_object.writerow([\"PassengerId\", \"Survived\"])\t# write the column headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model algorithm: Females survive, Males die\n",
    "Loop through each passenger in the train file:\n",
    " - if passenger is female, set as survived\n",
    " - if passenger is male,   set as died"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in test_file_object:\t\t\t\t\t\t\t\t\t# For each row in test file,\n",
    "    if row[3] == 'female':\t\t\t\t\t\t\t\t\t\t# is it a female, if yes then\n",
    "        predictions_file_object.writerow([row[0], \"1\"])\t\t\t# write the PassengerId, and predict 1\n",
    "    else:\t\t\t\t\t\t\t\t\t\t\t\t\t\t# or else if male,\n",
    "        predictions_file_object.writerow([row[0], \"0\"])\t\t\t# write the PassengerId, and predict 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_file.close()\t\t\t\t\t\t\t\t\t\t\t\t# Close out the files.\n",
    "predictions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
